{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `introdl` module is already installed.\n"
     ]
    }
   ],
   "source": [
    "# run this cell to ensure course package is installed\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "course_tools_path = Path('../../Lessons/Course_Tools/').resolve() # change this to the local path of the course package\n",
    "sys.path.append(str(course_tools_path))\n",
    "\n",
    "from install_introdl import ensure_introdl_installed\n",
    "ensure_introdl_installed(force_update=False, local_path_pkg= course_tools_path / 'introdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1707433896265,
     "user": {
      "displayName": "Jeff B",
      "userId": "12312427422906518493"
     },
     "user_tz": 360
    },
    "id": "l0lxuljjnyGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS_PATH=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\models\n",
      "DATA_PATH=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\data\n",
      "TORCH_HOME=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\n",
      "HF_HOME=C:\\Users\\bagge\\My Drive\\Python_Projects\\DS776_Develop_Project\\downloads\n"
     ]
    }
   ],
   "source": [
    "# add your imports and settings here\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Homework_01_scripts import make_spirals\n",
    "\n",
    "from introdl.utils import config_paths_keys\n",
    "\n",
    "paths = config_paths_keys()\n",
    "MODELS_PATH = paths['MODELS_PATH']\n",
    "DATA_PATH = paths['DATA_PATH']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcxjNSA3gGmV"
   },
   "source": [
    "# Binary classification of 2D points arranged in a spiral\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Read these carefully to be sure you don't leave anything out.\n",
    "\n",
    "Start by playing with the 2 class spiral classification problem in the [Neural Network Playground](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=spiral&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=35&networkShape=4,2&seed=0.76765&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&problem_hide=true&discretize_hide=true&regularization_hide=true&dataset_hide=true&regularizationRate_hide=true).  Note - this link gives you a reduced version of the original website so you can focus on mainly the structure of the NN for this assignment.  \n",
    "\n",
    "Don't change the test/training ratio or the noise level.  Also, use only X1 and X2 as features (inputs) for your network.  Experiment with the network structure and try retraining each network a few times until you find a network architecture that seems to work reasonably well.  Once you've done that  you should implement that network here in PyTorch.  \n",
    "\n",
    "We'll generate the initial spiral data for you.  You do the rest.  You should mimic the setup in the compact version of the logisitic regression notebook from class (in Canvas), but make changes to the network, training loop, etc. as needed.\n",
    "\n",
    "In addition to plotting the loss for the training and validation sets vs the epochs, figure out how to do the same for accuracy and share that plot.\n",
    "\n",
    "In the end you should be able to achieve 95% accuracy on the validation data.  I'll likely change a couple of random seeds to see if you've picked a robust architecture and training parameters!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you learned in NN Playground [5 pts]\n",
    "\n",
    "Use this cell to explain what you learned in NN playground.  What model did you select?  What learning rate?  What activation function?\n",
    "\n",
    "FILL IN HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data. [5 pts]\n",
    "\n",
    "We'll build the spirals and split the data into train and test sets.  We're using a larger training set than in NN playground for more robust training.  Don't modify this code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1707433896939,
     "user": {
      "displayName": "Jeff B",
      "userId": "12312427422906518493"
     },
     "user_tz": 360
    },
    "id": "WshMUYUjfUY7",
    "outputId": "22dcd674-eadf-4b81-80a2-c08d9f91f427"
   },
   "outputs": [],
   "source": [
    "# Execute, but don't change this cell to generate train and test data\n",
    "\n",
    "from Homework_01_scripts import make_spirals\n",
    "\n",
    "X, y = make_spirals(n_samples=1000, noise = 35, random_state = 42)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the Datasets and DataLoaders here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data [5 pts]\n",
    "\n",
    "Make side-by-side plots showing the training and test data along with the classes for each point.  You may have to look up how use matplotlib.pyplot.subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model [5 pts]\n",
    "\n",
    "Define your model.  Create an instance of it.  Use `summarizer` to generate a model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trainable parameters are in your model?\n",
    "\n",
    "ANSWER HERE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbfQJ6XyDKFz"
   },
   "source": [
    "## Train the model [5 pts]\n",
    "\n",
    "Configure the model training and do the training. Save the checkpoint file in MODELS_PATH.\n",
    "\n",
    "**You should be able to achieve around 95% accuracy on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707433897662,
     "user": {
      "displayName": "Jeff B",
      "userId": "12312427422906518493"
     },
     "user_tz": 360
    },
    "id": "pWnLQLZ_etOk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect convergence graphically [5 pts]\n",
    "\n",
    "Load the checkpoint file and use it to plot training and test loss vs epoch and training and test accuracy vs epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum test accuracy found by your model?\n",
    "\n",
    "ANSWER HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dj8B9rZFV-o0"
   },
   "source": [
    "## Visualize the model fit [5 pts]\n",
    "\n",
    "Plot the fitted model as in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707433897662,
     "user": {
      "displayName": "Jeff B",
      "userId": "12312427422906518493"
     },
     "user_tz": 360
    },
    "id": "-c5h-JBtXLTU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSobmn9ScsSd"
   },
   "source": [
    "Comment on the quality of the fit.  Does the decision boundary accurately represent the separation of the classes or is there anything about it that seems incorrect?\n",
    "\n",
    "ANSWER HERE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTZUbA102ZiC"
   },
   "source": [
    "## Make predictions [5 pts]\n",
    "\n",
    "Include a function for making predictions and find the probabilities and predicted labels for new points: (0,0), (0,2), and (0,4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1707434212334,
     "user": {
      "displayName": "Jeff B",
      "userId": "12312427422906518493"
     },
     "user_tz": 360
    },
    "id": "pihJAQ9xgS7H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1-HQWPweMIqAYecMoaiEwveKgKWaENYwo",
     "timestamp": 1707429755677
    }
   ]
  },
  "kernelspec": {
   "display_name": "DS776_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
