{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the Course Package\n",
    "\n",
    "* run the cell below\n",
    "* change `force_update = False` to avoid unecessary reinstalls\n",
    "* restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to ensure course package is installed\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "course_tools_path = Path('../../Lessons/Course_Tools/').resolve() # change this to the local path of the course package\n",
    "sys.path.append(str(course_tools_path))\n",
    "\n",
    "from install_introdl import ensure_introdl_installed\n",
    "ensure_introdl_installed(force_update=True, local_path_pkg= course_tools_path / 'introdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put all your imports here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8:  Sarcasm Detection\n",
    "\n",
    "Using the [\"Sarcasm_News_Headline\" dataset](https://huggingface.co/datasets/raquiba/Sarcasm_News_Headline) on HuggingFace you're going to try several approaches to sarcasm detection (text classification) and write a summary at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and split the dataset (2 points)\n",
    "\n",
    "While the dataset has \"train\" and \"test\" splits.  Ignore the \"test\" split since it almost entirely duplicates the \"train\" split.  \n",
    "\n",
    "Instead, use train_test_split with a seed of 42 to generate an 80/20 split of the original \"train\" split into training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Approach 1 - TF-IDF Vectors + ML Model (7 points)\n",
    "\n",
    "Include code to create TF-IDF Vectors that represent each headline.  Use these vectors to train a classification model (it doesn't have to be Logistic Regression).  Make predictions on the test set and generate a classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Approach 3 - Fine-tune DistilBert with Classification Head (7 points)\n",
    "\n",
    "Include code for set up, training, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Approach 4 - Part 1: Use an LLM Model and Zero-Shot Prompt (7 points)\n",
    "\n",
    "Using the `llm_classifier` helper function from the lesson apply your LLM classifier to the first 100 examples in the test set. Use a local model and an API-based model for comparison.  For the API-based model some possiblities include:\n",
    "* Groq: \"llama3-70b-8192\", (rate_limit = 30 requests per minute on free tier)\n",
    "* Together.AI: \"\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\" (rate limit = 10)\n",
    "* Gemini: \"gemini-flash-lite\" (rate_limit = 30 on free tier)\n",
    "\n",
    "Feel free to try others if you have access.\n",
    "\n",
    "Produce classification reports for both the local and best API-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_helpers import llm_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Approach 4 - Part 2: Use an LLM Model and Few-Shot Prompt (7 points)\n",
    "\n",
    "Build a few-shot prompt with three to five examples of each class and apply the same models used for the zero-shot prompt.  Produce classification reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize and Compare (6 points)\n",
    "\n",
    "Summarize the results from each of your models, comment briefly on each approach, and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Reflection (4 points)\n",
    "\n",
    "* What did you learn in this assignment?\n",
    "\n",
    "* What did you find hard to understand in this assignment?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
