{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 02\n",
    "\n",
    "In this notebook you'll explore, train, and evaluate models on the FashionMNIST dataset.  FashionMNIST was set up as a more difficult drop-in replacement for MNIST.\n",
    "\n",
    "For this assigment you'll want to use a CoCalc compute server with GPU.  Make sure you've watched the video at the beginning of the lesson about compute servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup (5 points)\n",
    "\n",
    "Train LeNet5Rev on FashionMNIST and evaluate the performance on the test set.  Include convergence plots of loss and accuracy on the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the model (24 pts)\n",
    "\n",
    "Try increasing the number of convolutional layers up to six with ReLU layers.  You many need to increase\n",
    "the number of channels (but not in every layer).  Use two max pooling layers.  Kernel size can be 3 or 5\n",
    "but adjust the padding so that the convolutional layers preserve the size of the feature maps.\n",
    "\n",
    "You can also simplify the classifier.  Try a single linear layer instead of multiple linear layers\n",
    "separated by ReLU functions.\n",
    "\n",
    "You should be able to achieve about 92% accuracy on the test set.  Show convergence plots for each model you try.   \n",
    "\n",
    "You should try at least three different models.  Describe your experiments.  For each experiment include the model and plot convergence results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the things you tried (3 pts)\n",
    "\n",
    "Summarize the network architectures you tried.  What worked best?  What didn't help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze your best model (8 pts)\n",
    "\n",
    "Make a confusion matrix for the predictions of your best model on the test set.  You can set `use_class_labels = True` when using `evaluate_classifier` to see the names of the classes.  You can also access the names of the classes as an attribute of the dataset, e.g. `dataset.classes`.\n",
    "\n",
    "Describe which classes get most confused by your model.  Plot examples of the images that your model is getting wrong.  Do these misclassifications make sense?  Are the images from the misclassified classes hard to distinguish by eye?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS776_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
